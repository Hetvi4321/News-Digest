{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Loading tokenizer for facebook/bart-large-cnn\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: huggingface.co\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/bart-large-cnn/resolve/main/tokenizer_config.json HTTP/11\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/bart-large-cnn/resolve/main/vocab.json HTTP/11\" 200 0\n",
      "DEBUG:root:Loading model for facebook/bart-large-cnn\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/bart-large-cnn/resolve/main/config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/bart-large-cnn/resolve/main/config.json HTTP/11\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/bart-large-cnn/resolve/main/generation_config.json HTTP/11\" 200 0\n",
      "DEBUG:root:Tokenizing input text\n",
      "DEBUG:root:Generating summary\n",
      "DEBUG:root:Summary generation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"summary\": \"default text size is 1.5 characters. Use the Daily Discussion to help people understand today's featured news stories. Use this week's Daily Discussion for help with reading comprehension and vocabulary. Use these questions to help readers understand today\\u2019s featured newsstories.\"}\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def summarize_text(text):\n",
    "    try:\n",
    "        model_name = 't5-base'\n",
    "        logging.debug(f\"Loading tokenizer for {model_name}\")\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        logging.debug(f\"Loading model for {model_name}\")\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "        logging.debug(\"Tokenizing input text\")\n",
    "        inputs = tokenizer.encode(\"summarize: \" + text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "        logging.debug(\"Generating summary\")\n",
    "        summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        logging.debug(\"Summary generation completed\")\n",
    "        return {\"summary\": summary}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in summarize_text: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Parameters (this will be replaced by Flask)\n",
    "# Set text_to_summarize from the previous function's output\n",
    "# text_to_summarize should be dynamically set\n",
    "\n",
    "output = summarize_text(text_to_summarize)\n",
    "print(json.dumps(output))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
